{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code will load the model information, generate the model definition, and run the model estimation using FSL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nipype.algorithms.modelgen as model   # model generation\n",
    "from  nipype.interfaces import fsl, ants      \n",
    "from nipype.interfaces.base import Bunch\n",
    "import os,json,glob,sys\n",
    "import numpy\n",
    "import nibabel\n",
    "import nilearn.plotting\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "datadir='/home/jovyan/ClassData/'\n",
    "    \n",
    "results_dir = '/home/jovyan/ClassData/LabResults'#os.path.abspath(\"../../results\")\n",
    "if not os.path.exists(results_dir):\n",
    "    os.mkdir(results_dir)\n",
    "\n",
    "from nipype.caching import Memory\n",
    "mem = Memory(base_dir='.')\n",
    "\n",
    "print('Using data from',datadir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from bids import BIDSLayout\n",
    "layout = BIDSLayout(datadir,validate=False)\n",
    "layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Psych60 Now lets look at what our data layout is a little closer.\n",
    "#BIDS format is described in more depth here http://bids.neuroimaging.io/\n",
    "#Please go and read up a little on BIDS and why it is important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout.get_subjects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout.get_tasks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_epi=layout.get(task=\"mental\", extensions=\"nii\")[0]\n",
    "layout.get(task=\"mental\", extensions=\"nii\")[0].path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#What does this tell us about this particular file?\n",
    "source_epi.entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Psych 60 please put answers inline\n",
    "#What happens if you change the [0] above to another number?\n",
    "layout.get(task=\"mental\", extensions=\"nii\")[0].path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Psych 60 \n",
    "#What does the number signify?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now please upload some sample onsets into your ClassData directory \n",
    "#then change onsets.txt to reflect the file you uploaded. \n",
    "#The files should be comma separated - this can be changed in Excel when you do Save As, CSV UFT-8 (Comma delimited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "events1 = pd.read_csv(os.path.join(datadir, \"onsets1.csv\"), sep=\",\")\n",
    "events2 = pd.read_csv(os.path.join(datadir, \"onsets2.csv\"), sep=\",\")\n",
    "events3 = pd.read_csv(os.path.join(datadir, \"onsets3.csv\"), sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset=600 #10 minute runs\n",
    "offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make offsets for our runs\n",
    "events2.onset=events2.onset+offset\n",
    "events3.onset=events3.onset+offset*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames=[events1,events2,events3]\n",
    "events=pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do you have the correct number of events?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for trial_type in events.trial_type.unique():\n",
    "    print(events[events.trial_type == trial_type])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Psych60\n",
    "#What did the above code do with the loop? Does this look correct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Psych60\n",
    "#Please save notebook before proceeding!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confoundfiles=layout.get(task=\"mental\", extensions=\"tsv\",subject='sid000006')\n",
    "confoundfiles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confounds1=pd.read_csv(confoundfiles[0].path,sep=\"\\t\", na_values=\"n/a\")\n",
    "confounds1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confounds1=pd.read_csv(confoundfiles[0].path,sep=\"\\t\", na_values=\"n/a\")\n",
    "confounds2=pd.read_csv(confoundfiles[1].path,sep=\"\\t\", na_values=\"n/a\")\n",
    "confounds3=pd.read_csv(confoundfiles[2].path,sep=\"\\t\", na_values=\"n/a\")\n",
    "frames=[confounds1,confounds2,confounds3]\n",
    "confounds=pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Psych60 - please answer inline\n",
    "#What regressors are we using? \n",
    "#What types of trials are we looking at?\n",
    "#What type of noise do they account for? Google is your friend for this part...\n",
    "\n",
    "info = [Bunch(conditions=['Social',\n",
    "                          'Event',\n",
    "                          'School',\n",
    "                          'Career'],\n",
    "              onsets=[list(events[events1.trial_type == 'Social'].onset),\n",
    "                      list(events[events1.trial_type == 'Event'].onset),\n",
    "                      list(events[events1.trial_type == 'School'].onset),\n",
    "                      list(events[events1.trial_type == 'Career'].onset)],\n",
    "              durations=[list(events[events1.trial_type == 'Social'].duration),\n",
    "                          list(events[events1.trial_type == 'Event'].duration),\n",
    "                          list(events[events1.trial_type == 'School'].duration),\n",
    "                          list(events[events1.trial_type == 'Career'].duration)],\n",
    "             regressors=[list(confounds1.FramewiseDisplacement.fillna(0)),\n",
    "                         list(confounds1.aCompCor00),\n",
    "                         list(confounds1.aCompCor01),\n",
    "                         list(confounds1.aCompCor02),\n",
    "                         list(confounds1.aCompCor03),\n",
    "                         list(confounds1.aCompCor04),\n",
    "                         list(confounds1.aCompCor05),\n",
    "                        ],\n",
    "             regressor_names=['FramewiseDisplacement',\n",
    "                              'aCompCor00',\n",
    "                              'aCompCor01',\n",
    "                              'aCompCor02',\n",
    "                              'aCompCor03',\n",
    "                              'aCompCor04',\n",
    "                              'aCompCor05',])\n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all preprocessed files for subject 6\n",
    "source_epi=layout.get(task=\"mental\", extensions=\"nii\", subject='sid000006')\n",
    "source_epi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#This part defines what is brain and what is not and if we wanted we could trim timepoints we didn't want by changing t_min \n",
    "#skip = mem.cache(fsl.ExtractROI)\n",
    "#skip_results1 = skip(in_file=source_epi[0].path,t_min=0, t_size=-1)\n",
    "#skip_results2 = skip(in_file=source_epi[1].path,t_min=0, t_size=-1)\n",
    "#skip_results3 = skip(in_file=source_epi[2].path,t_min=0, t_size=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Please read down to the bottom of this and answer questions before running:\n",
    "#What other ways are we removing noise?\n",
    "#Any other special parameters that we are using in the model?\n",
    "\n",
    "filelist=[source_epi[0].path, source_epi[1].path, source_epi[2].path]\n",
    "s = model.SpecifyModel()\n",
    "s.inputs.input_units = 'secs'\n",
    "s.inputs.functional_runs = source_epi[0].path#filelist#skip_results.outputs.roi_file\n",
    "s.inputs.time_repetition = 1 #1 second TR #layout.get_metadata(source_epi.filename)[\"RepetitionTime\"]\n",
    "s.inputs.high_pass_filter_cutoff = 128.\n",
    "s.inputs.subject_info = info\n",
    "specify_model_results = s.run()\n",
    "s.inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This sets up contrasts for each condition individually and then compares Lips vs others\n",
    "#Contrasts are the relative weight of the parameter estimates (betas) for each condition\n",
    "\n",
    "social_cond = ['Social','T', ['Social'],[1]]\n",
    "event_cond = ['Event','T', ['Event'],[1]]\n",
    "school_cond = ['School','T', ['School'],[1]]\n",
    "career_cond = ['School','T', ['School'],[1]]\n",
    "school_vs_others = [\"School vs. others\",'T', ['School', 'Event', 'Social','Career'],[1, -1/3, -1/3, -1/3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Psych 60\n",
    "#please write your own code for career_vs_others here\n",
    "#by copying and pasting the code above to below this line and modifying it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up one more contrast, an F contrast, think ANOVA\n",
    "\n",
    "#all_task = [\"All\", 'F', [social_cond, event_cond, school_cond]]\n",
    "contrasts=[social_cond, event_cond, school_cond, career_cond, school_vs_others]#, all_task]\n",
    "#[social_cond, event_cond, school_cond, career_cond, school_vs_others, career_vs_others, all_task]\n",
    "           \n",
    "level1design = mem.cache(fsl.model.Level1Design)\n",
    "level1design_results = level1design(interscan_interval = 1,#layout.get_metadata(source_epi.filename)[\"RepetitionTime\"],\n",
    "                                    bases = {'dgamma':{'derivs': True}},\n",
    "                                    session_info = specify_model_results.outputs.session_info,\n",
    "                                    model_serial_correlations=True,\n",
    "                                    contrasts=contrasts)\n",
    "\n",
    "level1design_results.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelgen = mem.cache(fsl.model.FEATModel)\n",
    "modelgen_results = modelgen(fsf_file=level1design_results.outputs.fsf_files,\n",
    "                            ev_files=level1design_results.outputs.ev_files)\n",
    "modelgen_results.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This shows our study design\n",
    "# What do each of the columns represent?\n",
    "desmtx=numpy.loadtxt(modelgen_results.outputs.design_file,skiprows=5)\n",
    "plt.imshow(desmtx,aspect='auto',interpolation='nearest',cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation matrix of our regressors \n",
    "#are any of them highly correlated? Would this be a problem?\n",
    "\n",
    "cc=numpy.corrcoef(desmtx.T)\n",
    "plt.imshow(cc,aspect='auto',interpolation='nearest', cmap=plt.cm.viridis)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mask = mem.cache(fsl.maths.ApplyMask)\n",
    "#mask_results = mask(in_file=skip_results.outputs.roi_file,\n",
    "#                    mask_file=os.path.join(datadir, \"derivatives\", \"fmriprep\", \n",
    "#                                        \"sub-%s\"%source_epi.subject, \"ses-%s\"%source_epi.session, \"func\", \n",
    "#                                        \"sub-%s_ses-%s_task-fingerfootlips_bold_space-mni152nlin2009casym_brainmask.nii.gz\"%(source_epi.subject,\n",
    "#                                                                                                                             source_epi.session)))\n",
    "#mask_results.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip = mem.cache(fsl.ExtractROI)\n",
    "skip_results1 = skip(in_file=source_epi[0].path,t_min=500, t_size=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mask=layout.get(space='MNI152NLin2009cAsym',suffix='brainmask',extension=\"nii.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = mem.cache(fsl.maths.ApplyMask)\n",
    "mask_results = mask(in_file=source_epi[0].path,mask_file='/home/jovyan/ClassData/sub-sid000006/func/sub-sid000006_task-mental_run-01_bold_space-MNI152NLin2009cAsym_brainmask.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_results.outputs.outfile #show us the filename of our masked EPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This section takes a LONG time. This may be as far as we make it during class today.\n",
    "#While this is running - how many timepoints does it say we have? How many timeseries?\n",
    "#Once this is done, how long did it take in total? How long do we need to allow to run all 3 runs for all participants?\n",
    "\n",
    "#Actually fit the GLM to our data: see https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FEAT/UserGuide#FILM_General_Linear_Model\n",
    "\n",
    "filmgls = mem.cache(fsl.FILMGLS)\n",
    "filmgls_results = filmgls(in_file=mask_results.outputs.out_file,\n",
    "                          design_file = modelgen_results.outputs.design_file,\n",
    "                          tcon_file = modelgen_results.outputs.con_file,\n",
    "                          fcon_file = modelgen_results.outputs.fcon_file,\n",
    "                          autocorr_noestimate = True)\n",
    "filmgls_results.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#This smooths each t map from our first run and displays them\n",
    "for t_map in filmgls_results.outputs.zstats:\n",
    "    nilearn.plotting.plot_glass_brain(nilearn.image.smooth_img(t_map, 8),\n",
    "                                      display_mode='lyrz', colorbar=True, plot_abs=False, threshold=2.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fstat\n",
    "#for t_map in [filmgls_results.outputs.zfstats]:\n",
    "#    nilearn.plotting.plot_glass_brain(nilearn.image.smooth_img(t_map, 8),\n",
    "#                                      display_mode='lyrz', colorbar=True, plot_abs=False, threshold=2.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filmgls_results.outputs.copes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#What are we talking about with copes in the code section below? \n",
    "#How did you define this in the script above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t_map in filmgls_results.outputs.copes:\n",
    "    nilearn.plotting.plot_glass_brain(nilearn.image.smooth_img(t_map, 8),\n",
    "                                      display_mode='lyrz', colorbar=True, plot_abs=False, vmax=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How are the t-stats different from the cope? See slides 37-60\n",
    "#https://fsl.fmrib.ox.ac.uk/fslcourse/lectures/feat1_part2.pdf\n",
    "for t_map in filmgls_results.outputs.tstats:\n",
    "    nilearn.plotting.plot_stat_map(nilearn.image.smooth_img(t_map, 8), colorbar=True, threshold=2.3)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
